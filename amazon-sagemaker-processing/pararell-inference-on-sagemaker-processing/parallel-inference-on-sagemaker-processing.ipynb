{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 大量のモデルでのバッチ推論を並列で行うサンプル\n",
    "\n",
    "テナントごとにモデルを作る必要があり、かつその数が大量である、というユースケースがあります。このようなユースケースにおいて、全てのモデルを使ってまとめてバッチ推論する際に、バッチ推論を並列化することで時間を短縮したいことがあります。このサンプルでは、SageMaker Processing Job を使って大量のモデルを使った並列バッチ推論を実現する方法を紹介します。\n",
    "\n",
    "このサンプルでは、大量にあるモデルを3グループに分けて並列バッチ推論します。以下のようにモデルと入力ファイルをフォルダ分けしています。自身の環境で利用する場合は、入力ファイル名から対応するモデルを取得できるよう命名規則を決めておいてください。\n",
    "\n",
    "```console\n",
    "models\n",
    "├── models1/\n",
    " | ├── model1.txt\n",
    " | └── model2.txt\n",
    "├── models2/\n",
    "└── models3/\n",
    "```\n",
    "\n",
    "```console\n",
    "data\n",
    "├── data1/\n",
    " | ├── data1.txt   // models1/model1 の入力ファイル\n",
    " | └── data2.txt   // models1/model2 の入力ファイル\n",
    "├── data2/        // models2 の中のモデルの入力ファイル\n",
    "└── data3/        // models3 の中のモデルの入力ファイル\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare resources\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "# from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.processing import Processor\n",
    "from sagemaker.image_uris import retrieve\n",
    "from datetime import datetime\n",
    "from dateutil import tz\n",
    "import os\n",
    "import time\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "region = sagemaker_session.boto_region_name\n",
    "role = get_execution_role()\n",
    "JST = tz.gettz('Asia/Tokyo')\n",
    "\n",
    "project_name = 'sagemaker-processing-parallel'\n",
    "user_name = 'demo'\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = 'sagemaker/proctest'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing Job の設定を作っていきます。`Processor` クラスに、使用するコンテナイメージのURL、コンテナ実行時に実行するコマンド、使用するインスタンスタイプと数などを設定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "code_path = '/opt/ml/processing/input/code'\n",
    "input_path = '/opt/ml/processing/input/data'\n",
    "model_path = '/opt/ml/processing/input/model'\n",
    "output_path = '/opt/ml/processing/output/data'\n",
    "\n",
    "image_uri = retrieve(\n",
    "    framework='sklearn',\n",
    "    version='1.0-1',\n",
    "    region=region,\n",
    "    py_version='py3',\n",
    "    instance_type='ml.m5.xlarge'\n",
    ")\n",
    "\n",
    "processor = Processor(\n",
    "    image_uri=image_uri,\n",
    "    entrypoint=[\"python3\", f\"{code_path}/predict.py\"],\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "        instance_type=\"ml.m5.xlarge\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload data\n",
    "モデルファイルを想定した models 以下のファイルを S3 にアップロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'models'\n",
    "models = sagemaker_session.upload_data(path=data_dir, bucket=bucket, key_prefix=prefix+'/models')\n",
    "print('input spec (in this case, just an S3 path): {}'.format(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "推論データを想定した data 以下のファイルを S3 にアップロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data'\n",
    "inputs = sagemaker_session.upload_data(path=data_dir, bucket=bucket, key_prefix=prefix+'/data')\n",
    "print('input spec (in this case, just an S3 path): {}'.format(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing Job 内で使用するコードを S3 にアップロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'code'\n",
    "code_s3_path = sagemaker_session.upload_data(path=data_dir, bucket=bucket, key_prefix=prefix+'/code')\n",
    "print('input spec (in this case, just an S3 path): {}'.format(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Processing job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このサンプルはモデルファイルが3つのパスに分割して保存されている想定のため Processing Job の起動を 3回ループして実行します。実行時に、モデルファイルと入力ファイルのパスを変更します。以下のセルを実行すると、3つの SageMaker Processing Job が起動します。Job の実行は 4分程度で終了します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "\n",
    "timestamp = datetime.now(JST).strftime('%Y%m%d-%H%M%S')\n",
    "\n",
    "model_dirs = [('models1','data1'), ('models2','data2'), ('models3','data3')]\n",
    "\n",
    "for i, (model_dir, data_dir) in enumerate(model_dirs):\n",
    "    print('Start inference job')\n",
    "    s3_model_path = os.path.join(models, model_dir)\n",
    "    print(s3_model_path)\n",
    "    s3_data_path = os.path.join(inputs, data_dir)\n",
    "    print(s3_data_path)\n",
    "    \n",
    "    job_base_name =  project_name + '-' + user_name + '-' + timestamp\n",
    "    job_name = job_base_name + str(i)\n",
    "    output_s3_path = f's3://{bucket}/{prefix}/{job_base_name}/output/result'\n",
    "\n",
    "    processor.run(\n",
    "        job_name=job_name,\n",
    "        inputs=[\n",
    "            ProcessingInput(\n",
    "                input_name='code',\n",
    "                source=code_s3_path,\n",
    "                destination=code_path),\n",
    "            ProcessingInput(\n",
    "                input_name='data',\n",
    "                source=s3_data_path,\n",
    "                destination=input_path),\n",
    "        ProcessingInput(\n",
    "                input_name='models',\n",
    "                source=s3_model_path,\n",
    "                destination=model_path)],\n",
    "        outputs=[\n",
    "            ProcessingOutput(source=output_path, destination=output_s3_path),\n",
    "        ],\n",
    "         arguments=['--code-path', code_path,\n",
    "                  '--input-data-path', input_path,\n",
    "                     '--model-path', model_path,\n",
    "                     '--job-id', str(i),\n",
    "                  '--output-data-path', output_path],\n",
    "        logs=False,\n",
    "        wait=False\n",
    "    )\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
